{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#summary","title":"Summary","text":"<p>Greenlight is a Blockstream service offering hosted, non-custodial, Lightning Network nodes to developers and  end-users. We take care of the infrastructure, while you are in  control of the keys.</p> <p>Nodes can be registered and started in seconds, perfect for new users that are just starting their Bitcoin and Lightning Network journey, developers wanting to provide their users with access to the Lightning Network, or hobbyists wanting to hack tools for their own use. It is not our goal to lock users into our infrastructure: once you've  gained experience running a node, you can off-board into your own  infrastructure, and we'll teach you how to do that too.</p>"},{"location":"#what-to-do-next","title":"What to do next?","text":"<p>Head over to the Getting Started page to learn  more about the Greenlight components and how to use them.</p>"},{"location":"about/","title":"About","text":"<p>Greenlight is a service by Blockstream, that offers hosted, non-custodial, Core-Lightning nodes to developers and end-users.</p> <p>Github  Discord </p>"},{"location":"about/changelog/","title":"Greenlight Service Changelog","text":""},{"location":"about/changelog/#2023","title":"2023","text":""},{"location":"about/changelog/#may","title":"May","text":"<ul> <li>Calls to <code>cln.Node/Invoice</code> now always include all possible    <code>routehints</code>. Possible in this case refers to channels with peers    that are currently in state <code>CHANNELD_NORMAL</code>, both disconnected    and connected.</li> </ul>"},{"location":"about/changelog/#june","title":"June","text":"<ul> <li>The JS bindings where clobbering the error messages due to    incorrect context use. Now we return errors as they are emitted.</li> <li>The scheduler no longer allows creating <code>regtest</code> nodes, since they    are unusable without a faucet to get coins for it.</li> </ul>"},{"location":"about/changelog/#july","title":"July","text":"<ul> <li>The <code>gl-plugin</code> will now wait for both the initial gossip sync and    the reconnection to the peers to complete, before allowing <code>pay</code>    through. This cuts down on spurious payment failures due to missing    peers or incomplete network view for routing.</li> <li>An issue concerning reconnecting to peers, if the signer attaches    before the underlying JSON-RPC has become available has been    fixed. This issue would cause peers to remain disconnected despite    a signer being attached. #210 &amp; #204</li> <li>The <code>gl-client</code> library and the language bindings have keepalive    messages enabled, with a timeout of 90 seconds. This ensures that    clients and signers that have been silently disconnected, e.g., by    suspending the device or losing network connectivity, will notice    and reconnect. #220</li> <li>The Node Domain has been enabled. This means that ever node now has    a unique URL at which the node can always be reached, without    having to explicitly schedule it first. This allows bypassing of    the scheduler, reducing the time required to start and connect to a    node.</li> </ul>"},{"location":"about/changelog/#september","title":"September","text":"<ul> <li>Temporarily removed the JS bindings. We will the bindings over to    uniffi, and the JS bindings were outdated and unused. But they'll    be back.</li> <li>The API has been simplified by removing methods that were both in    <code>greenlight.proto</code> as well as <code>node.proto</code>. The latter is from the    autogenerated <code>cln-grpc</code> which supercedes the <code>greenlight.proto</code>    methods.</li> </ul>"},{"location":"about/changelog/#november","title":"November","text":"<ul> <li>The methods that used to be in <code>greenlight.proto</code> that have been    superseded with the <code>node.proto</code> version have been removed on the    server side. The proto file now contains only Greenlight-specific    functionality (#317.</li> <li>Payment optimizations: we are working on getting the success rate    for payments up, and the time to completion down, focusing on    success rate first.</li> </ul>"},{"location":"about/faq/","title":"Frequently Asked Questions","text":""},{"location":"about/faq/#security","title":"Security","text":""},{"location":"about/faq/#can-the-server-cheat-by-broadcasting-an-old-state","title":"Can the server cheat by broadcasting an old state?","text":"<p>Context: Since the state of the node is stored on the server, could an attacker use the server state to cheat, i.e., close a channel with an outdated state?</p> <p>No, the signer needs to sign off. Greenlight uses CLN under the hood, and CLN defers signatures of the commitment transaction until the channel is getting closed. This means that the server will indeed have a stub of the commitment transaction, however it is missing the signer's signature. When closing the channel, CLN will request the signer to fill in the missing signature. Upon receiving the signature request the signer:</p> <ol> <li> <p>checks that the commitment corresponds to the latest state, i.e.,     no old and revoked state is being signed.</p> </li> <li> <p>updates its internal state to remember that this channel is being     closed, and it will never sign a newer commitment transaction     going forward.</p> </li> </ol> <p>All of this ensures that only ever the latest state gets signed, and that this signed state doesn't get revoked, making a cheat attempt impossible.</p>"},{"location":"getting-started/","title":"Overview","text":"<p>Before diving into the specifics, let's first define a number of concepts that will be useful once we start developing:</p>"},{"location":"getting-started/#nodes","title":"Nodes","text":"<p>Greenlight provisions and manages Core Lightning nodes on behalf of its users. The nodes expose the grpc interface defined in the <code>cln-grpc</code> proto file, without limitations. The goal of this guide is to spin up a node and interact with it as if it were a local Core Lightning node.</p>"},{"location":"getting-started/#authentication","title":"Authentication","text":"<p>All communication channels in Greenlight are authenticated and encrypted via mTLS (mutual Transport Layer Security). Each client receives its own identity in the form of a private key and matching certificate, which can then be used to authenticate and encrypt communication when talking with Greenlight.</p> <p>This guide uses two types of identities</p> <ul> <li>Developer identities can be used to register or recover Greenlight nodes.</li> <li>Device identities are used by applications to authenticate to single Greenlight    nodes. The private key is generated locally and will stay on your users    device.</li> </ul> <p>You can obtain a developer identity using the Greenlight Developer Console. When you register a node Greenlight will return a device identity. Alternatively, you can use request a new device identity for a node using the recover functionality.</p> <p>See the security page for more details about how the authentication works.</p>"},{"location":"getting-started/#signer","title":"Signer","text":"<p>The signer manages any private information, is used to prove node ownership when registering and recovering, and processes signature requests from the node. It is initialized with the secret seed (a 32 byte secret), the bitcoin network the node runs on, and the identity to use when communicating with the node.</p> <p>See the security page for details on how the signer ensures that operations it signs off originate from an authenticated app.</p>"},{"location":"getting-started/#scheduler","title":"Scheduler","text":"<p>Greenlight nodes are scheduled on-demand when a client needs to talk to it. The Scheduler tracks which nodes are running where, and starts them if they aren't running yet. You can think of it as just a mechanism to register new nodes and look up where they are running.</p>"},{"location":"getting-started/certs/","title":"Get a developer certificate","text":"<p>In order to build with Greenlight, you need a developer certificate. These are custom certificates that developers can bundle with their application, and that allow registering new nodes.</p> <p>You can create an account on the Greenlight Developer Console and download the zip file containing the certificate.</p>"},{"location":"getting-started/certs/#storing-the-certificate","title":"Storing the Certificate","text":"<p>The certificate is ditributed as two <code>x509</code> PEM files bundled into a zip file:</p> <ul> <li><code>client.crt</code>: this is the public certificate</li> <li><code>client-key.pem</code>: this is the private key matching the    above certificate and is used to encrypt the transport and    authenticate as a partner to the Scheduler.</li> </ul> <p>Consider these files as secrets. You should not include them in your code-repository but store them somewhere else instead. </p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#installing-the-library","title":"Installing the library","text":"<p>Greenlight provides client libraries for a variety of programming languages, providing an idiomatic interface to developers. The libraries allow interaction with both the Scheduler and the Node. The Scheduler provides access to the node metadata, while the Node is the user's CLN node running on Greenlight's infrastructure.</p> <p>Steps to install the library depend on the programming language and target environment. The code blocks below provide tabs for the most common ones:</p> RustPython <p>Add the <code>gl-client</code> crate as a dependency by either editing the <code>Cargo.toml</code> and add the following lines</p> <pre><code>[dependencies]\ngl-client = \"0.2\"\n</code></pre> <p>or by using <code>cargo add</code>:</p> <pre><code>cargo add gl-client\n</code></pre> <p>Note: the rust library currently relies on <code>git</code> dependencies, which crates.io does not allow. The <code>gl-client</code> library on crates.io is a placeholder until our dependencies stabilize.</p> <p>The <code>gl-client</code> package is available on the public PyPI:</p> <pre><code>pip install -U gl-client\n</code></pre> <p>If you use a different dependency management system please see its documentation about how to specify <code>gl-client</code> as a dependency.</p>"},{"location":"getting-started/recover/","title":"Recovering access to a node","text":"<p>One of the core benefits of Greenlight over self-hosted nodes is the ability to separate the state management in the form of the node database from the authorizing party, i.e., the <code>Signer</code>. This allows users to seamlessly recover access to their node in case of a boating accident, by simply proving ownership of the private key that corresponds to that node.</p> <p>In order to recover access all you need to do is recover the <code>seed</code> from the BIP39 seed phrase and initialize the <code>Signer</code> with it:</p> RustPython <pre><code>let seed = read_file(\"seed\");\nlet network = gl_client::bitcoin::Network::Bitcoin;\nlet creds = Nobody {\n    cert: nobody_cert,\n    key: nobody_key,\n    ..Nobody::default()\n};\n\nlet signer = gl_client::signer::Signer::new(seed, network, creds.clone()).unwrap();\n\nlet scheduler =\n    gl_client::scheduler::Scheduler::new(gl_client::bitcoin::Network::Bitcoin, creds)\n        .await\n        .unwrap();\n\nscheduler.recover(&amp;signer).await\n</code></pre> <pre><code>seed = read_file(\"seed\")\nnetwork = \"bitcoin\"\nsigner_creds = Credentials.nobody_with(developer_cert, developer_key)\nsigner = Signer(seed, network, signer_creds)\n\nscheduler = Scheduler(\n    network,\n    signer_creds,\n)\n\nscheduler_creds = signer_creds.upgrade(scheduler.inner, signer.inner)\n\nscheduler = Scheduler(\n    network,\n    scheduler_creds,\n)\n\nscheduler.recover(signer)\n</code></pre> <p>Notice that we are using a <code>TlsConfig</code> that is not configured with a client certificate and key, because that's what we're trying to recover. In the background the <code>scheduler</code> instance will contact the <code>Scheduler</code> service, retrieve a challenge, sign that challenge with the signer, and then call <code>recover</code> with that proof signature. The Scheduler will then check the challenge-response passed to <code>recover</code> and if successful, generate a new certificate for the client, which will provide access to the node.</p> <p>Important</p> <p>Remember to store the <code>device_cert</code> and <code>device_key</code> from the result so you can load it next time you want to interact with the node.</p>"},{"location":"getting-started/register/","title":"Register a node","text":"<p>In this section we'll use a developer certificate to register a node.</p> <p>We'll start with creating a seed that is used to derive node-secrets from. Each node on the lightning network is identified by a public key and the corresponding private key is one of these secrets. In the next step, we'll connect to the Scheduler using a developer identity and register the node. This requires you to prove that you own the private key mentioned previously.</p> <p>At the end of this section your node will be registered on Greenlight and you will have a device-identity that can be used to connect the node.</p>"},{"location":"getting-started/register/#creating-a-seed","title":"Creating a seed","text":"<p>Let's start with the seed secret: the seed secret is a 32 byte secret that all other secrets and private keys are derived from, as such it is paramount that this secret never leaves your user's device and is only handled by the Signer.</p> <p>We suggest to derive the seed secret from a BIP 39 seed phrase, so the user can back it up on a physical piece of paper, steel plate, or whatever creative way of storing it they can think of.</p> <p>Note</p> <p>The following code-snippets build on each other. By copying each snippet after the other you should get a working example. See the getting started project in examples to view the code in one file.</p> RustPython <p>Install the <code>bip39</code> and <code>rand</code> crates required for secure randomness and conversion of mnemonics. Add the following lines to your Cargo.toml</p> <pre><code>[dependencies]\nrand = \"*\"\nbip39 = { version = \"*\", features=[\"rand_core\"] }\n</code></pre> <p>Install the <code>bip39</code> package which we'll use to encode the seed secret as a seed phrase:</p> <pre><code>pip install bip39\n</code></pre> <p>Now we can securely generate some randomness, encode it as BIP 39 phrase and then convert it into a seed secret we can use:</p> RustPython <pre><code>let mut rng = rand::thread_rng();\nlet m = Mnemonic::generate_in_with(&amp;mut rng, Language::English, 24).unwrap();\n\n//Show seed phrase to user\nlet _phrase = m.word_iter().fold(\"\".to_string(), |c, n| c + \" \" + n);\n\nconst EMPTY_PASSPHRASE: &amp;str = \"\";\nlet seed = &amp;m.to_seed(EMPTY_PASSPHRASE)[0..32]; // Only need the first 32 bytes\n\n// Store the seed on the filesystem, or secure configuration system\nsave_to_file(\"seed\", seed.to_vec());\n</code></pre> <pre><code>rand = secrets.randbits(256).to_bytes(32, \"big\")  # 32 bytes of randomness\n\n# Show seed phrase to user\nphrase = bip39.encode_bytes(rand)\n\nseed = bip39.phrase_to_seed(phrase)[:32]  # Only need the first 32 bytes\n\n# Store the seed on the filesystem, or secure configuration system\nsave_to_file(\"seed\", seed)\n</code></pre> <p>Important</p> <p>Remember to store the seed somewhere (file on disk, registry, etc) because without it, you will not have access to the node, and any funds on the node will be lost forever! We mean it when we say you're the only one with access to the seed!</p>"},{"location":"getting-started/register/#initializing-the-signer","title":"Initializing the signer","text":"<p>To initialize a signer we'll first need to configure <code>Nobody</code> credentials so we can talk to the scheduler using mTLS. Nobody credentials require data from the files downloaded from the Greenlight Developer Console, so the files must be accessible from wherever the node registration program is run. Any connection using the <code>developer_creds</code> object will allow you to register new Greenlight nodes.</p> RustPython <pre><code>let developer_cert = std::fs::read(developer_cert_path).unwrap_or_default();\nlet developer_key = std::fs::read(developer_key_path).unwrap_or_default();\nlet developer_creds = Nobody {\n    cert: developer_cert,\n    key: developer_key,\n    ..Nobody::default()\n};\n</code></pre> <pre><code>developer_cert = Path(developer_cert_path).open(mode=\"rb\").read()\ndeveloper_key = Path(developer_key_path).open(mode=\"rb\").read()\n\ndeveloper_creds = Credentials.nobody_with(developer_cert, developer_key)\n</code></pre> <p>The next step is to create the <code>Signer</code> which processes incoming signature requests, and is used when registering a node to prove ownership of the private key. The last thing to decide is which network we want the node to run on. You can chose between the following networks:</p> <ul> <li><code>testnet</code></li> <li><code>bitcoin</code></li> </ul> <p>We'll pick <code>bitcoin</code>, because ... reckless \ud83d\ude09</p> RustPython <pre><code>let network = Network::Bitcoin;\nlet signer = Signer::new(seed, network, developer_creds.clone()).unwrap();\n</code></pre> <pre><code>network = \"bitcoin\"\nsigner = Signer(seed, network, developer_creds)\n</code></pre>"},{"location":"getting-started/register/#registering-a-new-node","title":"Registering a new node","text":"<p>Registering a node with the <code>Scheduler</code> creates the node on the Greenlight service and ensures everything is setup to start the node.</p> <p>In order to register a node, the client needs to prove it has access to the node's private key. Since the private key is managed exclusively by the <code>Signer</code> we need to pass the <code>Signer</code> to the <code>Scheduler</code>:</p> RustPython <pre><code>let scheduler = Scheduler::new(network, developer_creds).await.unwrap();\n\n// Passing in the signer is required because the client needs to prove\n// ownership of the `node_id`\nlet registration_response = scheduler.register(&amp;signer, None).await.unwrap();\n\nlet device_creds = Device::from_bytes(registration_response.creds);\nsave_to_file(\"creds\", device_creds.to_bytes());\n</code></pre> <pre><code>scheduler = Scheduler(network, developer_creds)\n\n# Passing in the signer is required because the client needs to prove\n# ownership of the `node_id`\nregistration_response = scheduler.register(signer, invite_code=None)\n\ndevice_creds = Credentials.from_bytes(registration_response.creds)\nsave_to_file(\"creds\", device_creds.to_bytes())\n</code></pre> <p>The result of <code>register</code> contains the credentials that can be used going forward to talk to the scheduler and the node itself. </p> <p>Important</p> <p>Please make sure to store them somewhere safe, since anyone with  these credentials can access your node.</p> RustPython <pre><code>let scheduler = scheduler.authenticate(device_creds).await.unwrap();\nlet _node: ClnClient = scheduler.node().await.unwrap();\n</code></pre> <pre><code>scheduler = scheduler.authenticate(device_creds)\nnode = scheduler.node()\n</code></pre> <p>If you get an error about a certificate verification failure when talking to the node, you most likely are using an unconfigured <code>TlsConfig</code> that doesn't have access to the node. See Security for details on how authentication and authorization work under the hood.</p>"},{"location":"getting-started/schedule/","title":"Starting a node","text":"<p>Now that the node has been registered on the Greenlight server, we can schedule it. Scheduling will tell the scheduler that we want to interact with the node, and need its GRPC URI, so we can talk to it. The scheduler will look up the node, check if it is currently running, and if not it'll start the node. It will then return the URL you can use to connect to the node directly.</p> <p>Important</p> <p>Currently nodes will get a new address whenever they are started, so don't cache the URL for longer periods of time. We spin nodes down if there is no client talking to it, and slots are reused for other nodes. Attempting to talk to a node that isn't yours will fail to establish a connection.</p> <p>The Greenlight team is working on an improvement that will assign a unique address to each node, ensuring that you always know how to reach the node, and allowing you to skip talking with the scheduler altogether.</p> <p>First of all we build an instance of the scheduler service stub, which will allow us to call methods on the service. We then schedule the node, which returns a stub representing the node running on the Greenlight infrastructure:</p> RustPython <pre><code>let network = Network::Bitcoin;\nlet device_creds = Device::from_path(device_creds_path);\nlet scheduler = gl_client::scheduler::Scheduler::new(network, device_creds.clone())\n    .await\n    .unwrap();\n\nlet mut node: gl_client::node::ClnClient = scheduler.node().await.unwrap();\n</code></pre> <pre><code>network = \"bitcoin\"\ndevice_creds = Credentials.from_path(device_creds_path)\nscheduler = Scheduler(network, device_creds)\n\nnode = scheduler.node()\n</code></pre> <p>Once we have an instance of the <code>Node</code> we can start interacting with it via the GRPC interface:</p> RustPython <pre><code>let _info = node.getinfo(cln::GetinfoRequest::default()).await.unwrap();\nlet _peers = node\n    .list_peers(gl_client::pb::cln::ListpeersRequest::default())\n    .await\n    .unwrap();\n</code></pre> <pre><code>info = node.get_info()\npeers = node.list_peers()\n</code></pre> <p>The above snippet will read the metadata and list the peers from the node. Both of these are read-only operations, that do not require a signer to sign off. What happens if we issue a command that requires a signer to sign off? Let's try to connect to create an invoice. Invoices are signed using the node key, and the signer is the only component with access to your key.</p> RustPython <pre><code>let amount = AmountOrAny {\n    value: Some(amount_or_any::Value::Amount(Amount { msat: 10000 })),\n};\n\nnode.invoice(cln::InvoiceRequest {\n    amount_msat: Some(amount),\n    description: \"description\".to_string(),\n    label: \"label\".to_string(),\n    ..Default::default()\n})\n.await\n.unwrap();\n</code></pre> <pre><code>node.invoice(\n    amount_msat=clnpb.AmountOrAny(amount=clnpb.Amount(msat=10000)),\n    description=\"description\",\n    label=\"label\",\n)\n</code></pre> <p>You'll notice that these calls hang indefinitely. This is because the signer is not running and not attached to the node, and without its signature we can't create the invoice. This isn't just the case for the <code>invoice</code> call either, all calls that somehow use the Node ID, or move funds, will require the signer's sign-off. You can think of a node without a signer being connected as a read-only node, and as soon as you attach the signer, the node becomes fully functional. So how do we attach the signer? Simple: load the secret from where you stored it in the last chapter, instantiate the signer with it and then start it.</p> RustPython <pre><code>let seed = read_file(\"seed\");\nlet signer = Signer::new(seed, network, device_creds.clone()).unwrap();\n\nlet (_tx, rx) = tokio::sync::mpsc::channel(1);\ntokio::spawn(async move {\n    signer.run_forever(rx).await.unwrap();\n});\n</code></pre> <p>Notice that <code>signer.run_forever()</code> returns a <code>Future</code> which you can spawn a new task with. That is also the reason why a separate shutdown signal is provided.</p> <pre><code>seed = read_file(\"seed\")\nsigner = Signer(seed, network, device_creds)\n\nsigner.run_in_thread()\n</code></pre> <p>If you kept the stuck commands above running, you should notice that they now return a result. As mentioned before many RPC calls will need the signer to be attached to the node, so it's best to just start it early, and keep it running in the background whenever possible. The signer will not schedule the node by itself, instead waiting on the scheduler, so it doesn't consume much resources, but still be available when it is needed.</p>"},{"location":"reference/","title":"References","text":"<p>Greenlight is based on the interplay a multitude of both novel and old concepts and components, whose necessity or inner workings may not be immediately apparent.</p> <p>In the following pages we aim to provide the necessary background and technical details to show how certain aspects are achieved in Greenlight. Each page focuses on a specific aspect or component and walks the readers through the issue that is being solved, how it is being solved, and may include some technical details necessary to recreate them</p> <p>Tip</p> <p>Besides this document, the documentation of the <code>gl-client</code> crate  provides some basic API reference. In order to build and explore the  rust docs of the <code>gl-client</code> crate locally use: <pre><code>cd libs/gl-client/\ncargo doc --open\n</code></pre></p>"},{"location":"reference/certs/","title":"Using the Certificate","text":"<p>In order to build with Greenlight, you need a certificate. These are custom certificates that developers can bundle with their application, and that allow registering new nodes.</p>"},{"location":"reference/certs/#how-to-get-a-certificate","title":"How to get a Certificate?","text":"<p>Create an account on the Greenlight Developer Console and download the zip file containing the certificate.</p>"},{"location":"reference/certs/#using-the-certificate_1","title":"Using the Certificate","text":"<p>The certificate is a custom version of the <code>/users/nobody</code> certificate that is used to bootstrap the trust chain for clients that have not yet received their own private key and certificate specific to their node. As such the private key and certificate are compiled into <code>gl-client</code> at build time.</p> <p>The certificate is ditributed as two <code>x509</code> PEM files bundled into a zip file:</p> <ul> <li><code>client.crt</code>: this is the certificate that the client will    present when connecting to the Scheduler in order to either    <code>register()</code> or <code>recover()</code>.</li> <li><code>client-key.pem</code>: this is the private key matching the    above certificate and is used to encrypt the transport and    authenticate as a partner to the Scheduler.</li> </ul> <p>Ideally the two files are then stored, securely, alongside the code, in encrypted form, or instrument your CI system to have access to them when building. Treat the private key with the same care you'd use for an API key, as they fulfill identical roles in this scenario.</p> <p>In order to tell the build to use the certificate you'll have to set two environment variables in the build environment. Please consult your build system and/or shell environment about how to ensure the build sees the variables.</p> <ul> <li><code>GL_CUSTOM_NOBODY_KEY</code> should have the absolute path to <code>client-key.pem</code></li> <li><code>GL_CUSTOM_NOBODY_CERT</code> should have the absolute path to <code>client.crt</code></li> </ul> <p>If either of these is not set you'll get a warning. This warning can be ignored if you are using an invite-code.</p> <pre><code>warning: Using default NOBODY cert.\nwarning: Set \"GL_CUSTOM_NOBODY_KEY\" and \"GL_CUSTOM_NOBODY_CERT\" to use a custom cert.\n</code></pre>"},{"location":"reference/certs/#providing-the-certificates-at-runtime","title":"Providing the certificates at runtime","text":"<p>In case you do not want to provide the certificate at compile-time, e.g., because you are using pre-compiled language bindings, you can also provide the certificates at runtime. The following code snippets show how to construct a <code>Signer</code> and a <code>Scheduler</code> instance with the certificates:</p> RustPython <pre><code>use gl_client::tls::{Signer, Scheduler, TlsConfig};\nlet tls = TlsConfig::new()?.identity(certificate, key);\n\nlet signer = Signer(seed, Network::Bitcoin, tls);\n\nlet scheduler = Scheduler::with(signer.node_id(), Network::Bitcoin, \"uri\", &amp;tls).await?;\n</code></pre> <pre><code>from glclient import TlsConfig, Signer, Scheduler\ntls = TlsConfig().identity(res.device_cert, res.device_key)\n\nsigner = Signer(seed, network=\"bitcoin\", tls=tls)\n\nnode = Scheduler(node_id=signer.node_id(), network=\"bitcoin\", tls=tls).node()\n</code></pre> <p>Notice that this is the same way that the <code>TlsConfig</code> is configured with the user credentials provided from the <code>register()</code> and <code>recover()</code> results.</p> <p>Important</p> <p>Certificates are credentials authenticating you as the developer of the Application, just like API keys. Do not publish the keys, as that would allow others to impersonate you.</p> <p>As for where the certificate may be stored, please use a location that is not easily accessible by users. Alternatively you can also provide them via from your servers gated behind an additional authentication layer.</p>"},{"location":"reference/certs/#when-not-to-use-the-certificate","title":"When (not) to use the certificate","text":"<p>In order to retain the protection aspect of the certificates please only use them in your own applications, and don't share them with others, directly or indirectly. In particular this means that you should not include them if you are building a library that others will use.</p>"},{"location":"reference/client-libraries/","title":"Client Libraries","text":"<p>We provide a number of client libraries and bindings for a variety of languages. The core logic is implemented in a small Rust crate called <code>gl-client</code>, on top of which the language bindings are built. Since these make use of native code they have to build a binary extension that can be loaded by the language runtime.</p> <p>We precompile the binaries for a couple of platforms and architectures to simplify installation for developers. These are automatically downloaded as part of the installation of the library and should your combination be supported you will not need any compiler or sophisticated build process, it should just work out of the box.</p>"},{"location":"reference/client-libraries/#platforms-and-architectures","title":"Platforms and Architectures","text":"<p>Currently our CI builds prebuilt bindings for Python for the following platform and architecture combinations:</p> OS Architecture MacOS x86_64 (intel) MacOS arm64 (m1/m2) Windows x86 Window x64 Linux x86_64-gnu Linux i686-gnu Linux armv7-gnueabi Linux aarch64 <p>Should your platform and architecture not be in the list above, don't worry, you can still build them from the source by checking out the repository, and then either call <code>make build-py</code> to build just the bindings you need.</p> <p>Please let us know if we're missing a combination, so we can try to add it to our build system, and remove the need to manually compile the extension going forward.</p> <p>There is an automated way of doing this in both languages, based on the source tarball published to NPM and PyPI, however since the build depends on a sibling crate which is not bundled it will most likely fail to build from source tarball (we are working on fixing this).</p>"},{"location":"reference/creds/","title":"Client Credentials","text":"<p>Greenlight utilizes various components, such as mTLS certificates and  runes, to provide secure access to a node.  Various pieces of data must be persisted and made available to the client  at runtime. Check out the Security page for more information.</p> <p>To simplify data management for users and developers, Greenlight uses  <code>Credentials</code> as a centralized location for the necessary information.  Credentials can be reconstructed in various ways and exported in  byte-encoded format for persistence.</p> <p>Tip</p> <p>If you registered your greenlight node before the release of gl-client v0.2, please see the section Instantiating a Credential from device certificates below.</p>"},{"location":"reference/creds/#credential-types","title":"Credential Types","text":"<p>There are two types of Credentials, the Nobody credential and the Device credential.</p> <p>Reference instantiations of both credentials types can be found below. Complete files can be viewed from the examples folder from which these code snippets were taken.</p>"},{"location":"reference/creds/#nobody-credentials","title":"Nobody Credentials","text":"<p>The Nobody credentials are used when there is no registered node associated with the requests made with the credential. They can be initialized using the developer certificates acquired from the Greenlight Developer Console and are used for registering and recovering greenlight nodes.</p> RustPython <pre><code>let developer_cert = std::fs::read(developer_cert_path).unwrap_or_default();\nlet developer_key = std::fs::read(developer_key_path).unwrap_or_default();\nlet developer_creds = Nobody {\n    cert: developer_cert,\n    key: developer_key,\n    ..Nobody::default()\n};\n</code></pre> <pre><code>developer_cert = Path(developer_cert_path).open(mode=\"rb\").read()\ndeveloper_key = Path(developer_key_path).open(mode=\"rb\").read()\n\ndeveloper_creds = Credentials.nobody_with(developer_cert, developer_key)\n</code></pre>"},{"location":"reference/creds/#device-credentials","title":"Device Credentials","text":"<p>The Device credentials are used when there is a registered node associated with the requests made with the credential. They can be restored from a path to a encoded credentials file, as well as from a byte array that carries the same data. <code>Credentials</code> for the device can also be constructed by their components or a combination of all of the above.</p> RustPython <pre><code>let device_creds = Device::from_bytes(registration_response.creds);\nsave_to_file(\"creds\", device_creds.to_bytes());\n</code></pre> <pre><code>device_creds = Credentials.from_bytes(registration_response.creds)\nsave_to_file(\"creds\", device_creds.to_bytes())\n</code></pre>"},{"location":"reference/creds/#instantiating-a-credential-from-device-certificates","title":"Instantiating a Credential from device certificates","text":"<p>For glclient versions released before v0.2, device certificates were the primary mechanism used for authentication. These certificates can be upgraded by instantiating a Device credential and invoking the upgrade method with a Nobody-instantiated Scheduler and a Signer. This will give the upgrade method everything it needs to construct any missing details and will return a properly functioning Device credential.</p> RustPython <pre><code>async fn upgrade_device_certs_to_creds(\n    scheduler: &amp;Scheduler&lt;Nobody&gt;,\n    signer: &amp;Signer,\n    device_cert: Vec&lt;u8&gt;,\n    device_key: Vec&lt;u8&gt;,\n) -&gt; Result&lt;Device&gt; {\n    Device {\n        cert: device_cert,\n        key: device_key,\n        ..Default::default()\n    }\n    .upgrade(scheduler, signer)\n    .await\n    .map_err(|e| anyhow!(\"{}\", e.to_string()))\n}\n</code></pre> <pre><code>def upgrade_device_certs_to_creds(\n    scheduler: Scheduler, signer: Signer, device_cert: bytes, device_key: bytes\n):\n    device_creds = Credentials.from_parts(device_cert, device_key, \"\")\n    return device_creds.upgrade(scheduler.inner, signer.inner)\n</code></pre>"},{"location":"reference/lsp/","title":"Lightning Service Provider integration","text":"<p>Greenlight nodes support the JIT LSP protocol. In particular the <code>gl-plugin</code> implements support for LSP JIT fees. These are fees leveraged as payment for a channel being opened, by forwarding a reduced amount, i.e., holding back a non-LN native fee. This is implemented on the LSP by intercepting and modifying the payload for the HTLC being forwarded, but this also causes the onion payload to mismatch the HTLC parameters (forwarded amount and total amount the sender intended to send). This would normally cause the recipient to fail the payment, however they are aware of this fee being leveraged, so we need to get the onion payload to match the HTLC and the corresponding invoice.</p> <p>The opt-in currently is determined by a matching invoice being present (payment_hash) and the sender values in the onion not matching the invoice. Hence the LSP needs to store a reduced invoice a the recipient node, but give out the original invoice to the prospective sender.</p>"},{"location":"reference/lsp/#caveats","title":"Caveats","text":"<ol> <li> <p>The LSP has to have the ability to know the amount that the    destination expects in order to satisfy that expectation. In order    to do so we need to have a couple of values match up:</p> <ol> <li> <p>Each HTLC value has to match or exceed the <code>amt_to_forward</code>     field in the destination's onion payload.</p> </li> <li> <p>The <code>total_msat</code> value at the end of the <code>payment_secret</code> onion     payload field has to match the sum of <code>amt_to_forward</code> values     communicated in the HTLCs (on overpayment we reject, since the     sender should have matched the expected amount exactly).</p> </li> </ol> <p>The first is simple to patch in <code>gl-plugin</code> since we just need to inspect the two values and adjust the one in the onion payload to match. The latter is not, but we can glimpse the expected value by looking up the invoice that is being paid. That does not work in the following two cases:</p> <ul> <li>Spontaneous payments: don't have a matching invoice, and we     can't decrypt the payload on the LSP to learn the amount the     sender intended to deliver. Since the LSP uses routehints in     invoices the sender would likely just not find a path.</li> <li>Amount-less invoices: same as above.</li> </ul> </li> </ol>"},{"location":"reference/node-domain/","title":"Node Domain","text":"<p>The Greenlight team is committed to providing users with full control over their Lightning nodes, which is why the ability to offboard from a hosted non-custodial node to a self-hosted setup is a key feature. We recognize that users may start with a hosted solution for convenience, but as their needs grow, they might prefer to manage their node on their own hardware or infrastructure. To facilitate this transition, we have implemented an export functionality that allows users to seamlessly move their node off our infrastructure. This feature disables the hosted node and provides users with an encrypted copy of their node's database. With this export, users can deploy their node independently, ensuring they retain control and ownership of their Lightning Network experience.</p> <p>Nodes can be exported entirely, including all of their funds and channel remaining intact. This means that apart from a brief downtime while the node is being exported and re-deployed, the hurdle to taking ownership of your own node is minimal.</p> <p>Users who wish to run a Lightning Network node behind a NAT (Network Address Translation) or firewall often face significant connectivity issues. The primary challenge is that NATs and firewalls typically block incoming connections, which prevents clients (such as wallets or other nodes) from being able to connect to the node. This lack of inbound connectivity is crucial for a non-custodial hosted Lightning node, since the user cannot access the node via their app, without configuring the network router or firewall.</p> <p>This is why we built the node domain server, a reverse proxy that smooths the user experience and hides the connection details behind a simple, publicly reachable URL.</p>"},{"location":"reference/node-domain/#enter-the-node-domain","title":"Enter the Node Domain","text":"<p>The node domain is a unique URL designed to provide seamless access to a user's Lightning node, regardless of its location \u2014 whether hosted on Greenlight's infrastructure or self-hosted by the user. The format of the URL is <code>gl1[node_id].gl.blckstrm.com</code>, where <code>[node_id]</code> is the <code>bech32m</code>-encoded Node ID for the user's node. This URL serves as a fixed endpoint that users and clients can rely on to connect to their node without needing to worry about the underlying network configuration or location.</p> <p>The functionality of the node domain is powered by a reverse proxy. When a connection request is made to the node domain, the reverse proxy processes the request and identifies the desired endpoint using Server Name Indication (SNI). SNI allows the proxy to determine which node the connection is intended for without decrypting the data stream, ensuring that the connection remains secure.</p> <p>Once  the  endpoint is  identified,  the  reverse proxy  forwards  the connection to the appropriate node:</p> <ul> <li> <p>Hosted Nodes: If the node is hosted on Greenlight's infrastructure,    the proxy checks if the node is currently active. If the node is not    running, Greenlight automatically schedules and starts the node to    handle the connection request.</p> </li> <li> <p>Self-Hosted Nodes: For self-hosted nodes, the process is slightly    different. The self-hosted node periodically reaches out to    Greenlight's tunnel server. This tunnel server maintains a    connection to the node, allowing the reverse proxy to forward    incoming connections through the tunnel, effectively exposing the    node to the internet. This approach eliminates the need for users    to configure NAT or firewall settings, making it easier to maintain    a self-hosted node.</p> </li> </ul> <p>In essence, the node domain provides a consistent and secure access point for users' Lightning nodes, abstracting away the complexities of node location and network configuration.</p>"},{"location":"reference/node-domain/#interpreting-errors","title":"Interpreting Errors","text":"<p>When using Server Name Indication (SNI) during the mutual TLS (mTLS) handshake, the node domain server faces a limitation in its ability to provide detailed error messages. This is because, during the mTLS handshake, the server does not decrypt the data stream, limiting itself to reading the unencrypted SNI fields in the handshake packets. The SNI is used solely to identify the desired endpoint (the specific node) before the encrypted stream is forwarded to the actual destination. At this stage, the server has very limited means to communicate back to the client, as the secure session has not yet been fully established.</p> <p>Due to these constraints, the server can only use the alert protocol defined in RFC 5246, section 7.2, to report any issues encountered during the scheduling process. The alert protocol is a part of the TLS specification that allows the server to send predefined, minimal error codes to the client, indicating that something has gone wrong. These alerts are intentionally brief and do not provide extended error details or context, which can make troubleshooting more difficult for clients interacting with the node domain.</p> <p>To mitigate this limitation, we utilize the custom range for alert codes within the alert protocol to encode specific, common issues that applications might encounter when connecting to the node domain. By doing so, we provide a more granular indication of what might have gone wrong during the connection attempt. While this approach still operates within the constraints of the TLS handshake, it enables the server to convey more specific errors than the standard TLS alerts, assisting in diagnosing problems more effectively.</p> <p>In summary, because the SNI is used before the data stream is decrypted, the node domain server is restricted to using the TLS alert protocol for error reporting. By leveraging custom alert codes, we can offer more meaningful feedback within these constraints, helping clients better understand and resolve connection issues.</p>"},{"location":"reference/node-domain/#tls-custom-alert-codes","title":"TLS Custom Alert Codes","text":"<ul> <li>221 (<code>InternalError</code>): A catch-all server-side error. If we don't    have more detailed information about what went wrong we return this    code. It does not indicate an error on the user's side, rather an    issue on the server that the Greenlight team needs to address.</li> <li>222 (<code>ReadSniError</code>): SNI (Server Name Indication, see RFC 6066,    Section3) is used to identify the desired node to    talk to. If the node domain server is unable to parse the SNI    header in the <code>ClientHelo</code> message this alert is returned. It    usually means that you are trying to talk to the servers with a    custom client. Please use the <code>gl-client</code> library.</li> <li>223 (<code>ConnectNodeError</code>): The node domain server has successfully    located the node, but failed to connect to it. This may either be a    stale scheduling in the hosted scenario, or a stale tunnel    connection from the self-hosted node.</li> <li>224 (<code>ConnectSchedulerError</code>): The node domain server was unable to    talk to the scheduler, and therefore could not locate, and/or    schedule, the node.</li> <li>225 (<code>SchedulerError</code>): The node domain server contacted the    scheduler correctly, but the scheduler was unable to locate or    schedule the node.</li> </ul> <p>Among these 221, 224 and 225 are considered server-side errors, and should be handled by the Greenlight team. Please escalate them to the team so we can identify the cause and address them. 222 and 223 are considered to be user errors, as stale sessions on the hosted offering are very unlikely, and therefore their appearance is mostly indicative of a user error.</p>"},{"location":"reference/security/","title":"Security","text":"<p>Each component in the Greenlight system is uniquely identified by an mTLS keypair, also called an identity. These are either used directly to setup mutually authenticated TLS connections, or to sign payloads in cases direct connections are not desirable or possible.</p> <p>In addition the signer also has access to the Bitcoin keypair that backs the Node ID, as well as the on-chain wallet. We will refer to this keypair as the signer-identity, whereas mTLS keypairs are just called the client-identities.</p> <p>In the following scenarios we will consider an attacker that has access to the node infrastructure, but not the client or the signer. This can either be an external attacker or a rogue Greenlight operator. Our goal is to prevent any access to funds from such an attacker, whether internal or external, by checking authorization on both the node as well as the signer level.</p>"},{"location":"reference/security/#client-node-authentication","title":"Client \u21c4 Node Authentication","text":"<p>This is a direct connection from a client to the node, or the signer to the node. The mTLS certificate hierarchy is under the control of the Greenlight Team. Each user gets their own CA, and nodes are configured to only accept client connections from certificates matching that CA. This guarantees that users can only contact their own node, while all other nodes would cause a mismatch and disconnect the client.</p> <p>Experimental</p> <p>Access to the node is currently all-or-nothing. The planned introduction of Rune-based access control will enable users to limit the operations a given client can execute. This is dependent on the pairing process as any client that has access to the signer could just escalate its privileges via the recovery.</p> <p>The private key for the client-identity is generated on the client itself, and never leaves the client, sending only a certificate signature request (CSR) to the scheduler which creates and signs the certificate. This puts the client in the correct subtree of the CA hierarchy, enabling it to contact the node.</p> <p>Impersonation by a potential attacker is prevented by keeping the private key for the client-identity on the client, and not share it with the server. Notice however that the Greenlight team, being in control of the CA hierarchy, could create a bogus client certificate and use that to issue commands to the node. More on this in the next section.</p>"},{"location":"reference/security/#client-signer-authentication","title":"Client \u21c4 Signer Authentication","text":"<p>The signer cannot rely on the mTLS CA structure, since that is under control of the Greenlight team. Instead, Greenlight employs an  attestation scheme in which the signer identity attests to itself and  other signers that a particular client is authorized to perform  certain operations.</p> <p>When registering a new client, the signer will submit a <code>rune</code> as an access token. The rune serves mainly as an authentication while the  client's identity in form of a mTLS key-pair provides authorization.  The run is bound to the client's identity; it is presented to the signer  on each request. This will allow multiple signers to recognize which  clients are authorized, even if the signer who carved the rune is not the  signer verifying the authorization.</p> <p>Before signing a request the signer independently verifies that:</p> <ol> <li>The operations that it is asked to sign off on match pending RPC     commands, and are safe to perform.</li> <li>The pending RPC commands are all signed by a valid client-identity</li> <li>The client-identity has a valid rune that qualifies for the request.</li> <li>None of the pending RPC commands is a replay of a previously     completed RPC command.</li> </ol> <p>An attacker that has gotten access to the node infrastructure may inject RPC commands directly into the node, side-stepping any authorization check on the node. For this reason the signer performs the same checks both on the node as well as the signer, the former preventing read-access that doesn't involve the signer, while the latter ensures funds are not moved without a client authorizing it.</p> <p>The client-identity pubkey, its signature of the command payload, and the rune are all passed to the node via grpc headers. The node  extracts them, alongside the call itself, and adds it to a request  context which will itself be attached to requests that are sent to the signer, so it can verify the validity and authenticity of the  operations. An attacker that gains access to the node is unable to  provide either these signatures and will therefore fail to convince the signer of its injected commands.</p>"},{"location":"reference/security/#client-signer-authorization","title":"Client \u21c4 Signer Authorization","text":"<p>The <code>rune</code>-based signer authentication verifies a client's  identity and their authorization to execute commands. To achieve more  granular control over command authorization for individual clients, a  rune can be created with specific restrictions. When verifying client  identity, the signer additionally ensures that specific conditions,  such as the requested command, align with the limitations of the given rune.</p> <p>This enables a user to share access to the signer across multiple  clients that are restricted to a subset of commands, for example  read-only clients, or invoice-only clients, or clients that can only create on-chain addresses and so on.</p>"},{"location":"reference/webhooks/","title":"Webhooks","text":""},{"location":"reference/webhooks/#webhooks","title":"Webhooks","text":"<p>Webhooks are URLs that receive HTTP requests containing event-related data. The application sending the event could be part of the hosting application or a different application entirely.</p> <p>With greenlight, developers can use webhooks to subscribe to events related to a given node. Up to 20 webhooks can be added per node and duplicate urls are permitted to help facilitate secret rotations.</p>"},{"location":"reference/webhooks/#events","title":"Events","text":"<p>Events are sent as HTTP POST requests with json payloads containing the details of the event. Events are structured in the following format:</p> <pre><code>{\n  \"version\": &lt;version&gt;,\n  \"node_id\": &lt;node_id&gt;,\n  \"event_type\": &lt;event_type&gt;\n}\n</code></pre>"},{"location":"reference/webhooks/#adding-a-webhook-to-a-greenlight-node","title":"Adding a webhook to a greenlight node","text":""},{"location":"reference/webhooks/#prerequisites","title":"Prerequisites","text":"<ul> <li>A public tls-secured endpoint </li> <li>Access to a greenlight node's device certificate</li> </ul> <p>To add a webhook for a greenlight node we first need to initialize a scheduler using the node id and device certificate (returned in the node registration response).</p> RustPython <pre><code>let device_cert = include_bytes!(\"path-to-device-cert\");\nlet device_key = include_bytes!(\"path-to-device-key\");\n\nlet credentials = Builder::as_device()\n    .with_identity(device_cert, device_key)\n    .build()\n    .expect(\"Failed to build Device credentials\");\n\nlet node_id = hex::decode(\"hex-node-id\").unwrap();\n\nlet scheduler = Scheduler::with_credentials(\n    node_id,\n    gl_client::bitcoin::Network::Bitcoin,\n    utils::scheduler_uri(),\n    credentials\n)\n.await\n.unwrap();\n</code></pre> <pre><code>from pathlib import Path\nfrom glclient import Credentials, TlsConfig\n\ncertpath = Path(\"device.pem\")\nkeypath = Path(\"device-key.pem\")\ncapath = Path(\"ca.pem\")\nrunepath = Path(\"rune\")\n\ncreds = Credentials.from_parts(\n    certpath.open(mode=\"rb\").read(),\n    keypath.open(mode=\"rb\").read(),\n    capath.open(mode=\"rb\").read(),\n    runepath.open(mode=\"rb\").read(),\n)\n\nnode_id = bytes.fromhex(\"hex-node-id\")\n\nscheduler = scheduler = Scheduler(\n    node_id=node_id,\n    network=\"bitcoin\",\n    creds=creds\n)\n</code></pre> <p>Once we're able to initialize the scheduler, we simply need to call <code>add_outgoing_webhook</code> with a well-formed url to finish adding the webhook. </p> <p>Don't forget to secure your webhook secrets</p> <p>Notice that we call <code>save_secret_to_db</code> to save the secret needed to validate webhook requests for this node. This secret cannot be recovered if lost and must be securely stored immediately after the addition of the webhook.</p> RustPython <pre><code>use gl_client::scheduler::Scheduler;\nuse gl_client::bitcoin::Network;\n\nlet webhook_uri = \"https://example.com\";\nlet add_webhook_response = scheduler.add_outgoing_webhook(webhook_uri).await.unwrap();\n\nsave_secret_to_db(signer.node_id(), &amp;add_webhook_response.secret);\n</code></pre> <pre><code>from glclient import Scheduler\n\nscheduler = Scheduler(\n    node_id=signer.node_id(),\n    network=\"bitcoin\",\n    tls=tls,\n)\n\nwebhook_uri = \"https://example.com\"\nscheduler.add_outgoing_webhook(webhook_uri)\n\nsave_secret_to_db(signer.node_id(), add_webhook_response.secret);\n</code></pre>"},{"location":"reference/webhooks/#verifying-webhook-payloads","title":"Verifying webhook payloads","text":"<p>Webhook payloads can be verified using the secret returned from <code>add_outgoing_webhook</code>. The secret can not be shared across nodes and is only valid for the node it was returned for. The secret serves as the key needed to validate the payload in an hmac-sha256 hash. If the payload is valid, the resulting hash should be equal to the base58-encoded value contained within the 'gl-signature' header of the request sent to the webhook.</p> RustPython <pre><code>use base64::Engine;\nuse hmac::{Hmac, Mac};\nuse sha2::Sha256;\n\nfn verify_signature(secret: &amp;String, gl_signature: &amp;String) -&gt; Result&lt;bool&gt; {\n    let mut hmac = match Hmac::&lt;Sha256&gt;::new_from_slice(secret.as_bytes()) {\n            Ok(m) =&gt; m,\n            Err(e) =&gt; Err(anyhow!(\"{:?}\", e))\n    };\n\n    hmac.update(&amp;message.as_bytes());\n    let hmac_output_bytes = hmac.finalize().into_bytes();\n\n    let engine = base64::engine::general_purpose::STANDARD;\n    match engine.encode(&amp;hmac_output_bytes) {\n        Ok(generated_signature) =&gt; Ok(generated_signature == gl_signature),\n        Err(e) =&gt; Err(anyhow!(\"{:?}\", e))\n    }\n}\n</code></pre> <pre><code>import hmac, hashlib, base64\n\ndef verify_signature(secret: str, body, sig) -&gt; bool:\n    payload_hmac = hmac.HMAC(\n            bytes(secret, \"UTF-8\"), body, digestmod=hashlib.sha256\n    )\n    base64_encoded_payload_hmac = base64.b64encode(\n            payload_hmac.digest()\n    )\n    return base64_encoded_payload_hmac.decode() == sig\n</code></pre>"},{"location":"reference/webhooks/#listing-webhooks","title":"Listing webhooks","text":"<p>Registered webhooks are uniquely identified for each node using an identifier called the webhook id. Calling <code>list_outgoing_webhooks</code> with a scheduler using the targeted node's device certificate will list all webhooks urls along with their uniquely generated webhook ids. This information is needed to delete a node's webhooks.</p> RustPython <pre><code>let outgoing_webhooks = scheduler.list_outgoing_webhooks().await.unwrap();\n</code></pre> <pre><code>outgoing_webhooks = scheduler.list_outgoing_webhooks();\n</code></pre>"},{"location":"reference/webhooks/#deleting-webhooks","title":"Deleting webhooks","text":"<p>Webhooks can be deleted by passing a webhook id to the scheduler's <code>delete_outgoing_webhook</code> or a list of webhook ids to <code>delete_outgoing_webhooks</code>.</p> RustPython <pre><code>let outgoing_webhooks = scheduler.delete_outgoing_webhooks(vec![1,2,3]).await.unwrap();\n</code></pre> <pre><code>scheduler.delete_outgoing_webhooks([1,2,3]);\n</code></pre>"},{"location":"reference/webhooks/#rotating-webhook-secrets","title":"Rotating webhook secrets","text":"<p>Rotating a webhook's secret invalidates the secret for a webhook id and generates a new secret that is then returned in the response. Once the rotate method is invoked, the existing secret is immediately invalidated. The recommended process for updating a webhook's secret is to add another webhook with the same url, rotate the old one, and delete the new one if a static webhook id is needed. If not, the old webhook id can be deleted instead of the new one in the last step.</p> <p>Note</p> <p>The payload must be hashed and verified before it's parsed as JSON to avoid any additional bytes from being added before signature validation. It's very important that the payload is not altered in anyway before its bytes are used as input to the HMAC.</p> RustPython <pre><code>let secret_response = scheduler.rotate_outgoing_webhook_secret(1).await.unwrap();\n</code></pre> <pre><code>secret_response = scheduler.rotate_outgoing_webhook_secret(1);\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Tutorials are self-contained walkthroughs, starting with a goal, and showing how to achieve this goal via step-by-step instructions. The aim of the tutorials in this section is to focus one aspect of Greenlight, from start to finish, and serve as an example of your own application.</p> <p>Note</p> <p>The information in these pages is primarily aimed at developers wanting to build on, or extend Greenlight, though end-users may find some of it interesting as well.</p>"},{"location":"tutorials/self-hosting/","title":"Self-Hosting Your Node","text":"<p>It is our goal to help you get started with the Lightning Network. However once you learned all that is required to run your own node, it is time to level up and approach the next challenge: managing your own node.</p> <p>For this purpose Greenlight allows users to export their nodes and restore it on their own infrastructure. This process can take a couple of minutes to complete, but it is faster and cheaper than migrating by shutting down the old node on GL, transferring all your funds, and having to bootstrap a new node from scratch.</p> <p>Under the hood we will:</p> <ol> <li>Mark the node as exported, so it doesn't start on GL going forward.</li> <li>Initiate a DB backup of the node's wallet database.</li> <li>Encrypt the DB backup so that it can be decrypted only by users     that have access to the seed phrase.</li> <li>Store the encrypted backup on a file store, from where it can be     downloaded, decrypted and restored locally by the user.</li> </ol> <p>Notice that step 1, marking the node as not-schedulable, is important for the security of the funds: if the node on GL were allowed to make progress it'd invalidate the backup, which could lead to channel closures.</p>"},{"location":"tutorials/self-hosting/#setup-your-infrastructure","title":"Setup Your Infrastructure","text":"<p>Before initiating the export, we will first need to prepare the new home where the node will be running going forward. The node running on Greenlight is a slightly modified Core Lightning node, with some of custom subdaemons and plugins. You can chose to replicate the same node by also running the custom subdaemons and plugins, or you can run a vanilla Core Lightning node. Custom components include the following:</p> <ul> <li><code>signerproxy</code> subdaemon: exposes the signer interface to the    signer, enabling the remote signer setup.</li> <li><code>gl-plugin</code> plugin: exposes the plugin interface, including mTLS    verification, and acts as a tailable signer request stream.</li> </ul> <p>If you'd like to continue using the remote signer you should use both <code>gl-plugin</code> and <code>signerproxy</code> in your own setup as well. If not you will have to create the <code>hsm_secret</code> file in the CLN config directory so that the stock CLN signer can find it and use it to run a local-only signer.</p> <p>If you have any clients configured you'll likely want to run the <code>gl-plugin</code> rather than the stock <code>grpc-plugin</code>, as the former implements a superset of the latter. In addition clients will still be able to reach the node through the node URL through the GL reverse proxy. In the next sections we provide step-by-step instructions to restore the node's database, and then setup the different variants. You will have to decide which one best suites your needs </p>"},{"location":"tutorials/self-hosting/#restoring-the-database","title":"Restoring the database","text":"Todo <p>Describe how to decrypt the backup and restore it into a new postgres database</p>"},{"location":"tutorials/self-hosting/#remote-signer-setup","title":"Remote Signer Setup","text":"Todo <p>Describe how to adjust the <code>lightningd</code> service to use the  <code>signerproxy</code> instead of the built-in <code>hsmd</code> subdaemon.</p>"},{"location":"tutorials/self-hosting/#local-signer-setups","title":"Local Signer Setups","text":"Todo <p>Should just work out of the box.</p>"},{"location":"tutorials/self-hosting/#minimal-setup","title":"Minimal Setup","text":"<p>The minimal setup to host an exported node consists of a PostgreSQL database, and a CLN installation matching or newer than the version that was running on Greenlight. Assuming the database is running locally with the credentials <code>pguser</code> and <code>pgpass</code> you' you'll have to run CLN node like this:</p> <pre><code>lightningd --wallet=postgres://pguser:pgpass@localhost:5432/dbname\n</code></pre>"},{"location":"tutorials/self-hosting/#initiate-export","title":"Initiate Export","text":"<p>The export can be triggered via the <code>Scheduler.export_node</code> method on the Scheduler's grpc interface. This method call may take a couple of minutes depending on the age of the node, the number of channels opened and closed, as well as the number of payments sent and received. Upon successful export the call will return a URL from a file host where the encrypted backup can be downloaded.</p> <p>Warning</p> <p>Once the state of the node has been switched you will no longer be able to schedule the node on Greenlight's infrastructure. We do not allow  re-activating the node because of the risk of a replica running somewhere  else, which could cause loss of funds!</p> <p>Do not worry if the connection is lost during this process, as the method is idempotent and will complete in the background if the connection is lost. Calling the method multiple times will results in the same encrypted backup URL</p>"},{"location":"tutorials/testing/","title":"Testing your Application","text":"<p>In this tutorial you will learn how to:</p> <ul> <li>Build and use the testing Docker image</li> <li>Set up a test network with Core Lightning nodes</li> <li>Use the Greenlight test framework <code>gl-testing</code></li> <li>Write a simple test that utilizes a Greenlight node</li> <li>Start a python REPL that lets you manually test against <code>gl-testing</code></li> </ul>"},{"location":"tutorials/testing/#why-test-and-what-to-test","title":"Why test and what to test?","text":"<p>You have just written the next viral app on top of Greenlight, how do you ensure it</p> <ol> <li>works now?</li> <li>keeps on working going forward?</li> </ol> <p>You could manually test your application after each change against the Greenlight servers, or you might even automate some of these, but they still run against the production environment. This is likely not as  fast as you're used to for local tests, and it actually allocates  resources on the Greenlight service that someone will have to pay for.</p> <p>It would undoubtedly be better if we had a way to test our application locally and in reproducible way. Well, fortunately, Greenlight  provides a testing framework that helps you do just that.</p>"},{"location":"tutorials/testing/#the-gl-testing-testing-framework","title":"The <code>gl-testing</code> testing framework","text":"<p>The Greenlight repository comes with a \"Batteries Included\"  testing framework that you can use to test your application locally. The testing framework <code>gl-testing</code> is based on pyln-testing which is also used in the development of Core Lightning itself.</p> <p>The components of <code>gl-testing</code> allow you to:</p> <ul> <li>Construct an arbitrarily complex network of lightning nodes.</li> <li>Set up a local mock of the Greenlight services.</li> <li>Use the provided pyln-fixtures for sophisticated test setups.</li> <li>Test your application in a repeatable and reproducible manner.</li> <li>Keep you system clean of development dependencies.</li> </ul> <p>Deviations in behavior between <code>gl-testing</code> and the production environment</p> <p>We keep track of the substantial differences in the behavior of  <code>gl-testing</code> and the production system in the  <code>gl-testing</code> readme</p> <p>This tutorial will walk you through the necessary steps to write a  test that registers a new Greenlight client with the <code>gl-testing</code>  testing framework that issues an invoice from the newly registered  Greenlight node. You will also learn how to start a REPL that you can use to manually execute commands against the testing framework or your application</p>"},{"location":"tutorials/testing/#prerequisites","title":"Prerequisites","text":""},{"location":"tutorials/testing/#git","title":"Git","text":"<p>The <code>gl-testing</code> testing framework is part of the Greenlight github repository. To get a local working copy of the Greenlight repository you need <code>git</code> installed on your system. See the  git-guides for a detailed instruction on how to install <code>git</code> on your system.</p>"},{"location":"tutorials/testing/#protoc","title":"protoc","text":"<p>The later section <code>Manually testing against a mock Network</code> requires us to build the <code>gl-client</code> on the host system. Greenlight uses grpc for the communication between the client and the node, therefor you need  the Protobuf compiler <code>protoc</code> present on our machine. Check out protoc for instructions on how to install <code>protoc</code> on your system.</p>"},{"location":"tutorials/testing/#docker","title":"Docker","text":"<p>Testing a Greenlight application is dependency intensive. We need  different versions of Core Lightning to be present besides a bunch of python packages, rust and cargo, as well as a compiler for proto  files. To help you keep your development environment clean, the  <code>gl-testing</code> testing framework comes with a Dockerfile that includes  all the necessary dependencies and allows you to run all the tests in  the shell of the assembled Docker image.</p> <p>You need a working Docker installation on your system in order to  build and use the Docker image. See the Docker manual for instructions on how to set up Docker on your operating system.</p> <p>Tip</p> <p>Testing in the docker images is optional for Linux hosts, but strongly suggested due to the rather large number of dependencies. For Windows and MacOS we only support testing in the docker image, since  Core Lightning only ships pre-compiled versions for Linux on  <code>x86_64</code> for now.</p>"},{"location":"tutorials/testing/#prepare-your-local-environment","title":"Prepare your local environment","text":"<p>Before we can dive into testing with the <code>gl-testing</code> testing framework we need to get a local working copy of the repository.</p> <pre><code>git clone git@github.com:Blockstream/greenlight.git gl-testing-tutorial\n</code></pre> <p>For the rest of the tutorial we will work within the repository we just cloned. <pre><code>cd gl-testing-tutorial\n</code></pre></p> <p>The Greenlight repository comes with a <code>Makefile</code> that holds some  useful targets for us. We make use of this to build a Docker image  <code>gltesting</code> that contains all the dependencies required to run the  testing framework <code>gl-testing</code>. <pre><code>make docker-image\n</code></pre></p> <p>Now we are all set and to drop into a shell that hold all the  required dependencies to work with <code>gl-testing</code>. <pre><code>make docker-shell\n</code></pre> You can always exit the docker-shell by calling <code>exit</code> from the shell  or by pressing <code>Ctrl-D</code>.</p> <p>Self testing</p> <p>You will probably have expected this, but we also use <code>gl-testing</code> to test the <code>gl-client</code> bindings themselves. If you are working on a pull request for the <code>gl-client</code> or another component,  <code>gl-testing</code> allows you to test your changes locally before  submitting them.</p>"},{"location":"tutorials/testing/#write-your-first-test","title":"Write your first test","text":"<p>Tests in <code>gl-testing</code> work best if you have a programmatic way of driving your client. This could either be your own testing framework, e.g., having a method to trigger a button press in your UI, or by exposing your own API. In this example we will walk through a simple  test that</p> <ol> <li>Sets up a small test network</li> <li>Starts a Greenlight node</li> <li>Opens a channel from the network to the Greenlight node</li> <li>Creates an invoice on the Greenlight node</li> <li>Pays the invoice from a node in the network</li> </ol> <pre><code>flowchart LR\n    A((CLN 1)) === B((CLN 2));\n    B === C((GL 1));\n    A -. payment .-&gt; C;</code></pre> <p>We start by creating our test file <code>my-first-test.py</code> in the root of  our <code>gl-testing-tutorial</code> directory. The <code>gl-testing</code> testing  framework uses the <code>pytest</code> framework under the hood, so writing test should be familiar for the python developers amongst you.</p> my-first-test.py<pre><code>from gltesting.fixtures import *\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    print(\"Hello World!\")\n</code></pre> <p>Here we import our test fixtures and create a simple test that just prints <code>\"Hello World!\"</code> to the standard output. Any function that  starts with <code>test_</code> will be picked up by the test runner and executed. The arguments are fixtures (see pytest for further details) that are passed to and can be used by the test.</p> <p>Let's check if we can properly import the <code>gl-testing</code> fixtures in our test. To run the test we need to drop to the shell of the Docker image we created above.</p> <pre><code>make docker-shell\n</code></pre> <p>Before we can run any tests that require parts of Greenlight, such as  the <code>gl-client</code>, the <code>gl-plugin</code> or any of the bindings, we need to build those components from the Docker shell.</p> <pre><code>make build-self\n</code></pre> <p>In the shell we execute the <code>pytest</code> command to run the test. We add the flags <code>-v</code> for a verbose output and <code>-s</code> to print all output to the console instead of capturing it.</p> <pre><code>pytest -v -s my-first-test.py\n</code></pre> <p>This should produce a lot of output, with the last few lines reading  something along the lines of <pre><code>Hello World!\nPASSED\nBitcoinRpcProxy shut down after processing 0 requests\nCalling stop with arguments ()\nResult for stop call: Bitcoin Core stopping\n\n\n============================================================ 1 passed in 4.10s =============================================================\n</code></pre></p> <p>Great! We have written our very first test. However, our test is still fairly useless, let's replace it with something actually meaningful.</p> <p>As a first step, we create a small network of Core Lightning nodes to  which we will connect our Greenlight node later on. Fortunately, <code>pyln-testing</code> provides us with some fixtures that handle common tasks for us. We can use this fixture to start and control  non-Greenlight nodes.</p> <p>my-first-test.py<pre><code>from gltesting.fixtures import *\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    # Create 2-node-network (l1)----(l2)\n    l1, l2 = node_factory.line_graph(2)\n    l2.fundwallet(sats=2*10**6)\n</code></pre> Here we used the <code>node_factory</code> fixture to create a <code>line-graph</code>  network consisting of two Core Lightning nodes <code>l1</code> and <code>l2</code> that  already have a channel established between them. The nodes have an  integrated rpc client that we can use to fund the <code>l2</code> node with  <code>2000000sat</code>.</p> <p>Tip: Use your IDEs autocompletion</p> <p>If you want to use the autocompletion features of your IDE you need to select the python interpreter form the environment set by  poetry in <code>libs/gl-testing</code>. You can then import the classes from  the fixtures and annotate the fixtures with its types. e.g.  <pre><code>from gltesting.fixtures import *\nfrom gltesting.fixtures import Clients\nfrom pyln.testing.fixtures import NodeFactory, LightningNode\n...\ndef test_xyz(node_factory: NodeFactory, clients: Clients):\n    nodes: list[LightningNode] = node_factory.line_graph(2)\n    l1, l2 = nodes[0], nodes[1]\n...\n</code></pre></p> <p>Now we can finally start to deal with Greenlight. We use the <code>clients</code>  fixture to create a new client, along with its own directory, signer  secret, and certificates. After that we can call the  <code>Client.register()</code> method to register the client with Greenlight and and <code>Client.node()</code> to schedule and return the Greenlight node that  belongs to the registered client. The <code>configure=True</code> argument tells the client to store the client certificates.</p> my-first-test.py<pre><code>from gltesting.fixtures import *\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    # Create 2-node-network (l1)----(l2)\n    l1, l2 = node_factory.line_graph(2)\n    l2.fundwallet(sats=2*10**6)\n\n    # Register a new Greenlight client.\n    c = clients.new()\n    c.register(configure=True)\n    gl1 = c.node()\n</code></pre> <p>Congratulations, we have our first Greenlight node up and running on the testing framework! </p> <p>Let's connect our Greenlight node to the  network now. To do so we need to establish a channel between our Greenlight node and the network. We choose the <code>l2</code> node as the entry point for our Greenlight node. Funding the channel between <code>l2</code> and  <code>gl</code> requires us to connect to <code>l2</code> and to fund a channel. The  connection handshake as well as the channel funding and eventually the creation of an invoice require the presence of a signer for the node. Greenlight signers run on the client side to keep the custody on the users side. We first need to start the client signer so that the node can request signatures from the signer.</p> my-first-test.py<pre><code>from gltesting.fixtures import *\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    # Create 2-node-network (l1)----(l2)\n    l1, l2 = node_factory.line_graph(2)\n    l2.fundwallet(sats=2*10**6)\n\n    # Register a new Greenlight client.\n    c = clients.new()\n    c.register(configure=True)\n    gl1 = c.node()\n\n    # Start signer and connect to (l2)\n    s = c.signer().run_in_thread()\n    gl1.connect_peer(l2.info['id'], f'127.0.0.1:{l2.daemon.port}')\n</code></pre> <p>We are almost there! Now we fund a channel between <code>l2</code> and <code>gl</code>. We  import a helper function  <code>from pyln.testing.utils import wait_for</code> that helps us to wait for the channel to be established.This will poll <code>gl1</code> for its channel states and return as soon as the state indicates that the channel is  confirmed and fully functional.</p> my-first-test.py<pre><code>from gltesting.fixtures import *\nfrom pyln.testing.utils import wait_for\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    # Create 2-node-network (l1)----(l2)\n    l1, l2 = node_factory.line_graph(2)\n    l2.fundwallet(sats=2*10**6)\n\n    # Register a new Greenlight client.\n    c = clients.new()\n    c.register(configure=True)\n    gl1 = c.node()\n\n    # Start signer and connect to (l2)\n    s = c.signer().run_in_thread()\n    gl1.connect_peer(l2.info['id'], f'127.0.0.1:{l2.daemon.port}')\n\n    # Fund a channel (l2)----(gl).\n    # This results in the following network\n    # (l1)----(l2)----(gl)\n    l2.rpc.fundchannel(c.node_id.hex(), 'all')\n    # Generate a block to synchronize and proceed\n    # with the channel funding.\n    bitcoind.generate_block(1, wait_for_mempool=1)\n    # Wait for the channel to confirm.\n    wait_for(lambda:\n        gl1.list_peers().peers[0].channels[0].state == 'CHANNELD_NORMAL'\n    )\n</code></pre> <p>Before we create and pay the invoice we also need to wait for the  gossip to reach every node. Otherwise the invoice will be lacking route hints as it assumes its only channel to be a dead end. Alternatively we could also create the invoice directly and wait for  <code>l1</code> to have a full view of our small network but lets go with the  first option this time. We again use the <code>wait_for</code> function. The successor function checks that we see 4 channel entries in our view of the network as both channels are bidirectional.</p> my-first-test.py<pre><code>from gltesting.fixtures import *\nfrom pyln.testing.utils import wait_for\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    # Create 2-node-network (l1)----(l2)\n    l1, l2 = node_factory.line_graph(2)\n    l2.fundwallet(sats=2*10**6)\n\n    # Register a new Greenlight client.\n    c = clients.new()\n    c.register(configure=True)\n    gl1 = c.node()\n\n    # Start signer and connect to (l2)\n    s = c.signer().run_in_thread()\n    gl1.connect_peer(l2.info['id'], f'127.0.0.1:{l2.daemon.port}')\n\n    # Fund a channel (l2)----(gl).\n    # This results in the following network\n    # (l1)----(l2)----(gl)\n    l2.rpc.fundchannel(c.node_id.hex(), 'all')\n    # Generate a block to synchronize and proceed\n    # with the channel funding.\n    bitcoind.generate_block(1, wait_for_mempool=1)\n    # Wait for the channel to confirm.\n    wait_for(lambda:\n        gl1.list_peers().peers[0].channels[0].state == 'CHANNELD_NORMAL'\n    )\n\n    # Wait for all channels to appear in our view of the network. We \n    # don't even have to wait for our channel to appear in l1s \n    # gossip: We can give a hint as soon as we know that our channel \n    # is not a dead end. We wait for 4 entries in our gossmap as both \n    # channels are bidirectional.\n    bitcoind.generate_block(5)\n    wait_for(\n        lambda: len([c for c in gl1.list_channels().channels]) == 4 \n    )\n</code></pre> <p>Now we can finally create and pay an invoice. We create an invoice on the Greenlight node and pay it with the <code>l1</code> node routed via the <code>l2</code> node. To create the invoice we import the core-lightning proto stubs <code>clnpb</code> from the Greenlight client <code>glclient</code>.</p> my-first-test.py<pre><code>from gltesting.fixtures import *\nfrom pyln.testing.utils import wait_for\nfrom glclient import clnpb\n\ndef test_invoice_payment(node_factory, clients, bitcoind):\n    # Create 2-node-network (l1)----(l2)\n    l1, l2 = node_factory.line_graph(2)\n    l2.fundwallet(sats=2*10**6)\n\n    # Register a new Greenlight client.\n    c = clients.new()\n    c.register(configure=True)\n    gl1 = c.node()\n\n    # Start signer and connect to (l2)\n    s = c.signer().run_in_thread()\n    gl1.connect_peer(l2.info['id'], f'127.0.0.1:{l2.daemon.port}')\n\n    # Fund a channel (l2)----(gl).\n    # This results in the following network\n    # (l1)----(l2)----(gl)\n    l2.rpc.fundchannel(c.node_id.hex(), 'all')\n    # Generate a block to synchronize and proceed\n    # with the channel funding.\n    bitcoind.generate_block(1, wait_for_mempool=1)\n    # Wait for the channel to confirm.\n    wait_for(lambda:\n        gl1.list_peers().peers[0].channels[0].state == 'CHANNELD_NORMAL'\n    )\n\n    # Wait for all channels to appear in our view of the network. We \n    # don't even have to wait for our channel to appear at the gossmap\n    # of l1: We can give a hint as soon as we know that our channel is \n    # not a dead end. We wait for 4 entries in our gossmap as both \n    # channels are bidirectional.\n    bitcoind.generate_block(5)\n    wait_for(\n        lambda: len([c for c in gl1.list_channels().channels]) == 4 \n    )\n\n    # Create an invoice.\n    bolt11 = gl1.invoice(\n        amount_msat=clnpb.AmountOrAny(amount=clnpb.Amount(msat=100000)),\n        description=\"test-desc\",\n        label =\"test-label\",\n    ).bolt11\n\n    # Pay invoice.\n    l1.rpc.pay(bolt11)\n</code></pre> <p>Congratulations! You have written your first test using the  <code>gl-testing</code> testing framework and a Greenlight node. Our test creates a small line graph network consisting of 3 lightning nodes with a  Greenlight node at the end. We created an invoice on the Greenlight node and payed for it with the first node in line.</p> <p>Let's check if our test passes!</p> <p>Remember that we need to call the tests from our docker shell <pre><code>make docker-shell\n</code></pre></p> <p>We can start our <code>pytest</code> test now. Remember the options <code>-v</code> and <code>-s</code> to print the logs to stdout instead of capturing them.  <pre><code>pytest -vs my-first-test.py\n</code></pre></p> <p>After the test is finished you should see <code>passed</code> in the terminal. <pre><code>========================================== 1 passed in 30.83s ===========================================\n</code></pre></p>"},{"location":"tutorials/testing/#manually-testing-against-a-mock-network","title":"Manually testing against a mock Network","text":"<p>Every once in a while you'll want to either step through an existing test, or have a small test that just sets up a network topology, and then drops you in a shell that you can use to interact with the network. In both cases <code>breakpoint()</code> is your friend.</p> <p>You also can use a <code>breakpoint()</code> to set up a <code>gltesting</code> environment that you can work against from your host.</p> <p>The following test will set up a small lightning network, and then  drops us in a REPL that we can use to inspect the setup, and to  drive changes such as paying an invoice or funding a channel. Note  that we also import and pass the <code>scheduler</code> <code>directory</code> fixtures to the test so that we can access them from our REPL:</p> examples/setup_repl.py<pre><code>from gltesting.fixtures import *\n\ndef test_setup(clients, node_factory, scheduler, directory, bitcoind):\n    \"\"\"Sets up a gltesting backend and a small lightning network.\n\n    This is meant to be run from inside the docker shell. See the \n    gltesting tutorial for further info.\n    \"\"\"\n    l1, l2, l3 = node_factory.line_graph(3)  # (1)!\n\n    # Assuming we want interact with l3 we'll want to print\n    # its contact details:\n    print(f\"l3 details: {l3.info['id']} @ 127.0.0.1:{l3.daemon.port}\")\n    print()\n    print(f\"export GL_CA_CRT={directory}/certs/ca.pem\")  # (4)\n    print(f\"export GL_NOBODY_CRT={directory}/certs/users/nobody.crt\")\n    print(f\"export GL_NOBODY_KEY={directory}/certs/users/nobody-key.pem\")\n    print(f\"export GL_SCHEDULER_GRPC_URI=https://localhost:{scheduler.grpc_port}\")  # (3)!\n\n    breakpoint()  # (2)!\n</code></pre> <ol> <li>At this point we have a network with 3 nodes in a line.</li> <li>Opens a REPL that accepts Python code.</li> <li>Tells us which port the mock scheduler is listening on</li> <li>Prints the location of the keypairs and certificates to use when     talking to the mock scheduler</li> </ol> <p>To run this test we first need to drop into the Docker shell. <pre><code>make docker-shell\n</code></pre></p> <p>Then we can start our REPL form inside the docker-shell. <pre><code>pytest -s examples/setup_repl.py\n</code></pre></p> <p>You will see an output that looks similar to the following lines: <pre><code>$ pytest -s testy.py\n========== test session starts ==========\nplatform linux -- Python 3.8.10, pytest-7.2.1, pluggy-1.0.0\nrootdir: /repo\nplugins: cov-3.0.0, xdist-2.5.0, forked-1.6.0, timeout-2.1.0\ncollected 1 item\n\ntesty.py Running tests in /tmp/ltests-syfsnw83\n[... many more lines about the setup of the network ...]\n\nscheduler: https://localhost:44165\nl3 details: **node_id** @ 127.0.0.1:40261\nexport GL_CA_CRT=/tmp/gltesting/**tmpdir**/certs/ca.pem\nexport GL_NOBODY_CRT=/tmp/gltesting/**tmpdir**/certs/users/nobody.crt\nexport GL_NOBODY_KEY=/tmp/gltesting/**tmpdir**/certs/users/nobody-key.pem\nexport GL_SCHEDULER_GRPC_URI=https://localhost:**scheduler_port**\n\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; PDB set_trace &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n--Return--\n&gt; /repo/testy.py(20)test_my_network()-&gt;None\n-&gt; breakpoint()\n(pdb)\n</code></pre></p> <p>At this point we have a REPL that we can use to drive changes  interactively, by writing python code, just like we'd do if we were  writing the test in a file.</p> <p>We now want to attach a client application from the host to the mock  scheduler. Therefore we first need to set a number of environment  variables on our host, that the <code>gl-client</code> library will pick up and  use. Just copy the following lines from your docker-shell:</p> <pre><code>export GL_CA_CRT=/tmp/gltesting/**tmpdir**/certs/ca.pem\nexport GL_NOBODY_CRT=/tmp/gltesting/**tmpdir**/certs/users/nobody.crt\nexport GL_NOBODY_KEY=/tmp/gltesting/**tmpdir**/certs/users/nobody-key.pem\nexport GL_SCHEDULER_GRPC_URI=https://localhost:**scheduler_port**\n</code></pre> <p>The first three lines tell the client library which identity to load itself, and how to verify the identity of the scheduler when connecting. These must match the lines printed above. The last line tells the client to connect to our mock scheduler instead of the production scheduler, the port must match the one printed above.</p> <p>Why is this random?</p> <p>We usually run tests in parallel, which requires that we isolate the tests from each other. If we did not randomize the ports and directories, we could end up with tests that interfere with each other, making debugging much harder, and resulting in flaky tests.</p> <p>We now can create a client on our host that we can mess around with.</p> <p>Lets have a look at the following example application that we will explain in more detail in another tutorial. You can find the file in the repository under <code>examples/app_test.py</code>.</p> examples/app_test.py<pre><code>import os\nimport pytest\nfrom glclient import Scheduler, Signer, TlsConfig,Node, nodepb\n\nclass GetInfoApp:\n    \"\"\"An example application for gltesting.\n\n    This example application shows the process on how to register,\n    scheduler and call against a gltesting environment greenlight \n    node.\n\n    To execute this example set up the docker gltesting environment,\n    drop into a REPL as explained in the gltesting tutorial.\n\n    Then run the test below outside the gltesting docker container\n    (run it from the host).\n    `pytest -s -v app_test.py::test_getinfoapp`.\n    \"\"\"\n    def __init__(self, secret: bytes, network: str, tls: TlsConfig):\n        self.secret: bytes = secret\n        self.network = network\n        self.tls: TlsConfig = tls\n        self.signer: Signer = Signer(secret, network, tls) # signer needs to keep running\n        self.node_id: bytes = self.signer.node_id()\n\n    def scheduler(self) -&gt; Scheduler:\n        \"\"\"Returns a glclient Scheduler\n\n        The scheduler is created from the attributes stored in this\n        class.\n        \"\"\"\n        return Scheduler(self.node_id, self.network, self.tls)\n\n    def register_or_recover(self):\n        \"\"\"Registers or recovers a node on gltesting\n\n        Also sets the new identity after register/recover.\n        \"\"\"\n        res = None\n        try:\n            res = self.scheduler().register(self.signer)\n        except:\n            res = self.scheduler().recover(self.signer)\n\n        self.tls = self.tls.identity(res.device_cert, res.device_key)\n\n    def get_info(self) -&gt; nodepb.GetInfoResponse:\n        \"\"\"Requests getinfo on the gltesting greenlight node\"\"\"\n        res = self.scheduler().schedule()\n        node = Node(self.node_id, self.network, self.tls, res.grpc_uri)\n        return node.get_info()\n\n\ndef test_getinfoapp():\n    # These are normally persisted on disk and need to be loaded and\n    # passed to the glclient library by the application. In this \n    # example we store them directly in the \"app\".\n    secret = b'\\x00'*32\n    network='regtest'\n    tls = TlsConfig()\n\n    # Register a node\n    giap = GetInfoApp(secret, network, tls)\n    giap.register_or_recover()\n\n    # GetInfo\n    res = giap.get_info()\n    print(f\"res={res}\")\n</code></pre> <p>This example application registers a node and requests <code>getinfo</code> on the greenlight node. Let's check if we can run it agains our REPL gltesting setup.</p> <p>We need to switch to the example directory (on our host, not in the  docker-shell) and activate the python environment that sets up all  the necessary dependencies for the example.</p> <pre><code>poetry shell\n</code></pre> <pre><code>poetry install\n</code></pre> <p>The first command drops us into a <code>poetry</code>-shell, the second installs the necessary dependencies from the <code>pyproject.toml</code> file.</p> <p>With the REPL setup in the docker-shell and from the poetry-shell on  the host we can now run our test application.</p> <pre><code>pytest -s app_test.py::test_getinfoapp\n</code></pre> <p>If you now see something an output that looks similar to the following lines, you made it! You successfully set up a <code>gltesting</code> greenlight mock in the <code>docker-shell</code> an application against it from the host.</p> <pre><code>================== test session starts ==================\n...                                                        \napp_test.py::test_getinfoapp res=id: \"\\002\\005\\216\\213l*\\323c\\354Y\\252\\023d)%mtQd\\302\\275\\310\\177\\230\\360\\246\\206\\220\\354,\\\\\\233\\013\"\nalias: \"VIOLENTSPAWN-v23.05gl1\"\ncolor: \"\\002\\005\\216\"\nversion: \"v23.05gl1\"\nlightning_dir: \"/tmp/gltesting/tmp/tmpdz6neih7/node-0/regtest\"\nour_features {\n  init: \"\\010\\240\\210\\n\\\"i\\242\"\n  node: \"\\210\\240\\210\\n\\\"i\\242\"\n  invoice: \"\\002\\000\\000\\002\\002A\\000\"\n}\nblockheight: 103\nnetwork: \"regtest\"\nfees_collected_msat {\n}\n\nPASSED\n\n================== 1 passed in 0.10s ==================\n</code></pre> <p>All of this works thanks because we mount the <code>/tmp/gltesting</code> directory from the host, allowing both, the docker container and host to exchange files. The <code>docker-shell</code> also reuses the host network, allowing clients or applications running on the host to talk directly to the  scheduler and the nodes running in the docker container.</p> <p>Once you are done testing, use <code>continue</code> or <code>Ctrl-D</code> in the REPL to trigger a shutdown.</p>"}]}